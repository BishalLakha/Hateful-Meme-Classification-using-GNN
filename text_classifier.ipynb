{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "import numpy as np\n",
    "\n",
    "from utils.utils import *\n",
    "from models.gcn import GCN\n",
    "from models.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bis/Projects/Classes/Deeplearning_class/project/utils/utils.py:242: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    }
   ],
   "source": [
    "# Loading graph\n",
    "adj, features,base_features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(word2vec=True)\n",
    "\n",
    "features_with_word2vec = preprocess_features(features)\n",
    "\n",
    "features = sp.identity(features.shape[0])\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bis/Projects/venv3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Loading image features\n",
    "train_embeddings, test_embeddings = get_image_embeddings()\n",
    "training_embeddings = torch.tensor(train_embeddings).reshape(train_size,512)\n",
    "test_embeddings = torch.tensor(test_embeddings).reshape(test_size,512)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Wac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = \"./data/additional_data/meme_vocab.txt\"\n",
    "wac_data = loadWAC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = open(vocab_file, 'r')\n",
    "all_word_embeddings = []\n",
    "for word in vocab.readlines():\n",
    "    word = word.strip()\n",
    "\n",
    "    try:\n",
    "        word_embedding = wac_data[word]\n",
    "        word_embedding = torch.tensor(word_embedding).reshape(1,512)\n",
    "    except:\n",
    "        word_embedding = torch.zeros((1,512))\n",
    "    all_word_embeddings.append(word_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings_words  = torch.cat(all_word_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine wac and image representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting complete features for all nodes\n",
    "word_nodes = features.shape[0] - train_size - test_size\n",
    "\n",
    "# Since we don't have image embeddings for words, we will use zeros\n",
    "\n",
    "all_image_features = torch.cat((training_embeddings, image_embeddings_words, test_embeddings), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20050, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0091, -0.0294,  0.1800,  ...,  0.1068,  0.0904,  0.0022],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.2614, -0.0073, -0.1738,  ...,  0.4274,  0.2315,  0.0266],\n",
       "        ...,\n",
       "        [-0.0298,  0.0187, -0.1962,  ..., -0.1138,  0.0497,  0.0509],\n",
       "        [ 0.0569,  0.1939, -0.0819,  ...,  0.2075, -0.2659, -0.0912],\n",
       "        [-0.2407,  0.0551, -0.0462,  ...,  0.1517,  0.2010,  0.0911]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj + sp.eye(adj.shape[0]))\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "adjdense = torch.from_numpy(pre_adj(adj).A.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True\n",
    "def construct_graph(adjacency):\n",
    "    g = DGLGraph()\n",
    "    adj = pre_adj(adjacency)\n",
    "    g.add_nodes(adj.shape[0])\n",
    "    g.add_edges(adj.row,adj.col)\n",
    "    adjdense = adj.A\n",
    "    adjd = np.ones((adj.shape[0]))\n",
    "    for i in range(adj.shape[0]):\n",
    "        adjd[i] = adjd[i] * np.sum(adjdense[i,:])\n",
    "    weight = torch.from_numpy(adj.data.astype(np.float32))\n",
    "    g.ndata['d'] = torch.from_numpy(adjd.astype(np.float32))\n",
    "    g.edata['w'] = weight\n",
    "\n",
    "    if CUDA:\n",
    "        g = g.to(torch.device('cuda:0'))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv(nn.Module):\n",
    "    def __init__(self,g,in_feats,out_feats,activation,feat_drop=True):\n",
    "        super(SimpleConv, self).__init__()\n",
    "        self.graph = g\n",
    "        self.activation = activation\n",
    "        #self.reset_parameters()\n",
    "        setattr(self, 'W', nn.Parameter(torch.randn(in_feats,out_feats)))\n",
    "        #self.b = nn.Parameter(torch.zeros(1, out_feats))\n",
    "        #self.linear = nn.Linear(in_feats,out_feats)\n",
    "        self.feat_drop = feat_drop\n",
    "    \n",
    "    # def reset_parameters(self):\n",
    "    #     gain = nn.init.calculate_gain('relu')\n",
    "    #     nn.init.xavier_uniform_(self.linear.weight,gain=gain)\n",
    "    \n",
    "    def forward(self, feat):\n",
    "        g = self.graph.local_var()\n",
    "        g.ndata['h'] = feat.mm(getattr(self, 'W'))\n",
    "        g.update_all(fn.src_mul_edge(src='h', edge='w', out='m'), fn.sum(msg='m',out='h'))\n",
    "        rst = g.ndata['h']\n",
    "        #rst = self.linear(rst)\n",
    "        rst = self.activation(rst)\n",
    "        return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_feats, out_feats):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.graph = g\n",
    "        setattr(self, 'W', nn.Parameter(torch.randn(in_feats,out_feats)))\n",
    "        setattr(self, 'al', nn.Parameter(torch.randn(in_feats,1)))\n",
    "        setattr(self, 'ar', nn.Parameter(torch.randn(in_feats,1)))\n",
    "\n",
    "    def forward(self, feat):\n",
    "        # equation (1)\n",
    "        g = self.graph.local_var()\n",
    "        g.ndata['h'] = feat.mm(getattr(self, 'W'))\n",
    "        g.ndata['el'] = feat.mm(getattr(self, 'al'))\n",
    "        g.ndata['er'] = feat.mm(getattr(self, 'ar'))\n",
    "        g.apply_edges(fn.u_add_v('el', 'er', 'e'))\n",
    "        # message passing\n",
    "        g.update_all(fn.src_mul_edge('h', 'w', 'm'), fn.sum('m', 'h'))\n",
    "        e = F.leaky_relu(g.edata['e'])\n",
    "        # compute softmax\n",
    "        g.edata['w'] = F.softmax(e)\n",
    "        rst = g.ndata['h']\n",
    "        #rst = self.linear(rst)\n",
    "        #rst = self.activation(rst)\n",
    "        return rst\n",
    "\n",
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, activation, num_heads=2, merge=None):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            x = torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            x = torch.mean(torch.stack(head_outs),dim=0)\n",
    "        \n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEMeanConv(nn.Module):\n",
    "    def __init__(self,g,in_feats,out_feats,activation):\n",
    "        super(SAGEMeanConv, self).__init__()\n",
    "        self.graph = g\n",
    "        self.feat_drop = nn.Dropout(0.5)\n",
    "        setattr(self, 'W', nn.Parameter(torch.randn(in_feats,out_feats)))\n",
    "        #self.linear = nn.Linear(in_feats, out_feats, bias=True)\n",
    "        setattr(self, 'Wn', nn.Parameter(torch.randn(out_feats,out_feats)))\n",
    "        self.activation = activation\n",
    "        #self.neigh_linear = nn.Linear(out_feats, out_feats, bias=True)\n",
    "        # self.reset_parameters()\n",
    "    \n",
    "    '''\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_uniform_(self.linear.weight,gain=gain)\n",
    "        nn.init.xavier_uniform_(self.neigh_linear.weight,gain=gain)\n",
    "    '''\n",
    "    \n",
    "    def forward(self,feat):\n",
    "        g = self.graph.local_var()\n",
    "        #feat = self.feat_drop(feat)\n",
    "        h_self = feat.mm(getattr(self, 'W'))\n",
    "        g.ndata['h'] = h_self\n",
    "        g.update_all(fn.copy_src('h', 'm'), fn.sum('m', 'neigh'))\n",
    "        h_neigh = g.ndata['neigh']\n",
    "        degs = g.in_degrees().float()\n",
    "        degs = degs.to(torch.device('cuda:0'))\n",
    "        g.ndata['h'] = (h_neigh + h_self) / (degs.unsqueeze(-1) + 1)\n",
    "        rst = g.ndata['h']\n",
    "        rst = self.activation(rst)\n",
    "        # rst = th.norm(rst)\n",
    "        return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_word2vec = torch.tensor(features_with_word2vec).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifer(nn.Module):\n",
    "    def __init__(self,g,input_dim,num_classes,conv):\n",
    "        super(Classifer, self).__init__()\n",
    "        self.data_graph = g\n",
    "        self.GCN = conv\n",
    "        self.gcn1 = self.GCN(g,input_dim, 300, F.relu)\n",
    "        self.gcn2 = self.GCN(g, 300, 200, F.relu)\n",
    "        self.gcn3 = self.GCN(g, 200, num_classes, F.relu)\n",
    "\n",
    "    \n",
    "    def forward(self, features):\n",
    "        x = self.gcn1(features)\n",
    "\n",
    "        # To Do: Fuse the text embedding with image embedding \n",
    "        self.embedding = x\n",
    "        # x = torch.cat(x,g.ndata['x'])\n",
    "        # x = torch.cat((self.embedding,g.ndata['x']),dim=1)\n",
    "        x = self.gcn2(x)\n",
    "        x = self.gcn3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ClassiferFusion(nn.Module):\n",
    "    def __init__(self,g,input_dim,num_classes,conv):\n",
    "        super(ClassiferFusion, self).__init__()\n",
    "        self.data_graph = g\n",
    "        self.GCN = conv\n",
    "        self.gcn1 = self.GCN(g,input_dim, 300, F.relu)\n",
    "        self.gcn2 = self.GCN(g, 300, 512, F.relu)\n",
    "        self.gcn3 = self.GCN(g, 1024,num_classes , F.relu)\n",
    "        # self.gcn4 = self.GCN(g, 300, num_classes, F.relu)\n",
    "        # self.gcn5 = self.GCN(g, 300, num_classes, F.relu)\n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, features):\n",
    "        x = self.gcn1(features)\n",
    "\n",
    "        self.embedding1 = x\n",
    "        # x = torch.cat(x,g.ndata['x'])\n",
    "        # Mean of text embedding and word2vec\n",
    "        x = torch.mean(torch.stack((self.embedding1,features_with_word2vec.float())),dim=0)\n",
    "\n",
    "        # # Concatenate the text embedding with image embedding        \n",
    "\n",
    "        x = self.gcn2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        self.embedding2 = x\n",
    "        x = torch.cat((self.embedding2,g.ndata['image_embeddings']),dim=1)\n",
    "\n",
    "        x = self.gcn3(x)\n",
    "        x = self.dropout(x)\n",
    "        # x = self.gcn4(x)\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.gcn5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bis/Projects/venv3.6/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "g = construct_graph(adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding node features image_embeddings\n",
    "all_image_features = all_image_features.cuda()\n",
    "g.ndata['image_embeddings'] = all_image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ClassiferFusion(g,input_dim=features.shape[0], num_classes=y_train.shape[1],conv=MultiHeadGATLayer)\n",
    "# model = Classifer(g,input_dim=features.shape[0], num_classes=y_train.shape[1],conv=MultiHeadGATLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "t_features = torch.from_numpy(features.astype(np.float32))\n",
    "t_y_train = torch.from_numpy(y_train)\n",
    "t_y_val = torch.from_numpy(y_val)\n",
    "t_y_test = torch.from_numpy(y_test)\n",
    "t_train_mask = torch.from_numpy(train_mask.astype(np.float32))\n",
    "tm_train_mask = torch.transpose(torch.unsqueeze(t_train_mask, 0), 1, 0).repeat(1, y_train.shape[1])\n",
    "support = [preprocess_adj(adj)]\n",
    "num_supports = 1\n",
    "t_support = []\n",
    "for i in range(len(support)):\n",
    "    t_support.append(torch.Tensor(support[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_features = t_features.cuda()\n",
    "t_y_train = t_y_train.cuda()\n",
    "#t_y_val = t_y_val.cuda()\n",
    "#t_y_test = t_y_test.cuda()\n",
    "t_train_mask = t_train_mask.cuda()\n",
    "tm_train_mask = tm_train_mask.cuda()\n",
    "# for i in range(len(support)):\n",
    "#     t_support = [t.cuda() for t in t_support if True]\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01,weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(features, labels, mask):\n",
    "    t_test = time.time()\n",
    "    # feed_dict_val = construct_feed_dict(\n",
    "    #     features, support, labels, mask, placeholders)\n",
    "    # outs_val = sess.run([model.loss, model.accuracy, model.pred, model.labels], feed_dict=feed_dict_val)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features).cpu()\n",
    "        t_mask = torch.from_numpy(np.array(mask*1., dtype=np.float32))\n",
    "        tm_mask = torch.transpose(torch.unsqueeze(t_mask, 0), 1, 0).repeat(1, labels.shape[1])\n",
    "        loss = criterion(logits * tm_mask, torch.max(labels, 1)[1])\n",
    "        pred = torch.max(logits, 1)[1]\n",
    "        acc = ((pred == torch.max(labels, 1)[1]).float() * t_mask).sum().item() / t_mask.sum().item()\n",
    "        \n",
    "    return loss.numpy(), acc, pred.numpy(), labels.numpy(), (time.time() - t_test)\n",
    "\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bis/Projects/venv3.6/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/4/20 13:45:12] Epoch: 1, train_loss= 0.74704, train_acc= 0.60341, val_loss= 0.86229, val_acc= 0.52400, time= 1.21737\n",
      "[2022/4/20 13:45:13] Epoch: 2, train_loss= 0.74464, train_acc= 0.60624, val_loss= 0.85394, val_acc= 0.52400, time= 1.24508\n",
      "[2022/4/20 13:45:14] Epoch: 3, train_loss= 0.73731, train_acc= 0.61294, val_loss= 0.84681, val_acc= 0.52200, time= 1.23505\n",
      "[2022/4/20 13:45:16] Epoch: 4, train_loss= 0.73251, train_acc= 0.61376, val_loss= 0.84131, val_acc= 0.52600, time= 1.20263\n",
      "[2022/4/20 13:45:17] Epoch: 5, train_loss= 0.72986, train_acc= 0.61141, val_loss= 0.83678, val_acc= 0.52000, time= 1.22045\n",
      "[2022/4/20 13:45:18] Epoch: 6, train_loss= 0.72787, train_acc= 0.61153, val_loss= 0.83270, val_acc= 0.51800, time= 1.23414\n",
      "[2022/4/20 13:45:19] Epoch: 7, train_loss= 0.72584, train_acc= 0.61224, val_loss= 0.82887, val_acc= 0.52200, time= 1.21790\n",
      "[2022/4/20 13:45:21] Epoch: 8, train_loss= 0.72373, train_acc= 0.61529, val_loss= 0.82514, val_acc= 0.52600, time= 1.21962\n",
      "[2022/4/20 13:45:22] Epoch: 9, train_loss= 0.72159, train_acc= 0.61847, val_loss= 0.82140, val_acc= 0.51800, time= 1.24616\n",
      "[2022/4/20 13:45:23] Epoch: 10, train_loss= 0.71958, train_acc= 0.62059, val_loss= 0.81764, val_acc= 0.51800, time= 1.23550\n",
      "[2022/4/20 13:45:24] Epoch: 11, train_loss= 0.71777, train_acc= 0.62047, val_loss= 0.81401, val_acc= 0.51400, time= 1.26142\n",
      "[2022/4/20 13:45:26] Epoch: 12, train_loss= 0.71618, train_acc= 0.62094, val_loss= 0.81059, val_acc= 0.51400, time= 1.24966\n",
      "[2022/4/20 13:45:27] Epoch: 13, train_loss= 0.71482, train_acc= 0.61976, val_loss= 0.80737, val_acc= 0.51000, time= 1.26740\n",
      "[2022/4/20 13:45:28] Epoch: 14, train_loss= 0.71364, train_acc= 0.61882, val_loss= 0.80456, val_acc= 0.51000, time= 1.22542\n",
      "[2022/4/20 13:45:29] Epoch: 15, train_loss= 0.71273, train_acc= 0.61788, val_loss= 0.80219, val_acc= 0.50600, time= 1.26588\n",
      "[2022/4/20 13:45:31] Epoch: 16, train_loss= 0.71201, train_acc= 0.61788, val_loss= 0.80007, val_acc= 0.50200, time= 1.29466\n",
      "[2022/4/20 13:45:32] Epoch: 17, train_loss= 0.71130, train_acc= 0.61847, val_loss= 0.79808, val_acc= 0.50400, time= 1.26808\n",
      "[2022/4/20 13:45:33] Epoch: 18, train_loss= 0.71055, train_acc= 0.61847, val_loss= 0.79616, val_acc= 0.50600, time= 1.26287\n",
      "[2022/4/20 13:45:34] Epoch: 19, train_loss= 0.70974, train_acc= 0.61871, val_loss= 0.79426, val_acc= 0.49800, time= 1.29222\n",
      "[2022/4/20 13:45:36] Epoch: 20, train_loss= 0.70890, train_acc= 0.61965, val_loss= 0.79234, val_acc= 0.49800, time= 1.27300\n",
      "[2022/4/20 13:45:37] Epoch: 21, train_loss= 0.70808, train_acc= 0.62035, val_loss= 0.79034, val_acc= 0.50000, time= 1.25306\n",
      "[2022/4/20 13:45:38] Epoch: 22, train_loss= 0.70730, train_acc= 0.62035, val_loss= 0.78821, val_acc= 0.50400, time= 1.24227\n",
      "[2022/4/20 13:45:39] Epoch: 23, train_loss= 0.70654, train_acc= 0.62059, val_loss= 0.78599, val_acc= 0.50200, time= 1.25070\n",
      "[2022/4/20 13:45:41] Epoch: 24, train_loss= 0.70585, train_acc= 0.62082, val_loss= 0.78379, val_acc= 0.50400, time= 1.25408\n",
      "[2022/4/20 13:45:42] Epoch: 25, train_loss= 0.70524, train_acc= 0.62094, val_loss= 0.78176, val_acc= 0.50200, time= 1.25251\n",
      "[2022/4/20 13:45:43] Epoch: 26, train_loss= 0.70471, train_acc= 0.62129, val_loss= 0.77987, val_acc= 0.50400, time= 1.24245\n",
      "[2022/4/20 13:45:44] Epoch: 27, train_loss= 0.70425, train_acc= 0.62094, val_loss= 0.77814, val_acc= 0.50800, time= 1.22127\n",
      "[2022/4/20 13:45:46] Epoch: 28, train_loss= 0.70383, train_acc= 0.62059, val_loss= 0.77657, val_acc= 0.50800, time= 1.24712\n",
      "[2022/4/20 13:45:47] Epoch: 29, train_loss= 0.70339, train_acc= 0.62082, val_loss= 0.77509, val_acc= 0.50600, time= 1.20915\n",
      "[2022/4/20 13:45:48] Epoch: 30, train_loss= 0.70293, train_acc= 0.62129, val_loss= 0.77370, val_acc= 0.50200, time= 1.23724\n",
      "[2022/4/20 13:45:49] Epoch: 31, train_loss= 0.70244, train_acc= 0.62118, val_loss= 0.77240, val_acc= 0.50400, time= 1.23016\n",
      "[2022/4/20 13:45:51] Epoch: 32, train_loss= 0.70198, train_acc= 0.62200, val_loss= 0.77110, val_acc= 0.50400, time= 1.19543\n",
      "[2022/4/20 13:45:52] Epoch: 33, train_loss= 0.70154, train_acc= 0.62224, val_loss= 0.76978, val_acc= 0.50200, time= 1.20639\n",
      "[2022/4/20 13:45:53] Epoch: 34, train_loss= 0.70112, train_acc= 0.62271, val_loss= 0.76847, val_acc= 0.50000, time= 1.23633\n",
      "[2022/4/20 13:45:54] Epoch: 35, train_loss= 0.70075, train_acc= 0.62271, val_loss= 0.76722, val_acc= 0.50200, time= 1.21828\n",
      "[2022/4/20 13:45:55] Epoch: 36, train_loss= 0.70044, train_acc= 0.62224, val_loss= 0.76597, val_acc= 0.50200, time= 1.20153\n",
      "[2022/4/20 13:45:57] Epoch: 37, train_loss= 0.70017, train_acc= 0.62141, val_loss= 0.76472, val_acc= 0.49600, time= 1.21016\n",
      "[2022/4/20 13:45:58] Epoch: 38, train_loss= 0.69992, train_acc= 0.62141, val_loss= 0.76348, val_acc= 0.49800, time= 1.22955\n",
      "[2022/4/20 13:45:59] Epoch: 39, train_loss= 0.69966, train_acc= 0.62047, val_loss= 0.76225, val_acc= 0.50200, time= 1.22641\n",
      "[2022/4/20 13:46:00] Epoch: 40, train_loss= 0.69934, train_acc= 0.62071, val_loss= 0.76109, val_acc= 0.50400, time= 1.20784\n",
      "[2022/4/20 13:46:02] Epoch: 41, train_loss= 0.69901, train_acc= 0.62024, val_loss= 0.76009, val_acc= 0.50400, time= 1.23055\n",
      "[2022/4/20 13:46:03] Epoch: 42, train_loss= 0.69868, train_acc= 0.62071, val_loss= 0.75913, val_acc= 0.50800, time= 1.22208\n",
      "[2022/4/20 13:46:04] Epoch: 43, train_loss= 0.69834, train_acc= 0.62024, val_loss= 0.75823, val_acc= 0.50800, time= 1.21937\n",
      "[2022/4/20 13:46:05] Epoch: 44, train_loss= 0.69800, train_acc= 0.62047, val_loss= 0.75730, val_acc= 0.50600, time= 1.23305\n",
      "[2022/4/20 13:46:06] Epoch: 45, train_loss= 0.69767, train_acc= 0.62059, val_loss= 0.75641, val_acc= 0.50400, time= 1.28560\n",
      "[2022/4/20 13:46:08] Epoch: 46, train_loss= 0.69733, train_acc= 0.62094, val_loss= 0.75557, val_acc= 0.51000, time= 1.21731\n",
      "[2022/4/20 13:46:09] Epoch: 47, train_loss= 0.69698, train_acc= 0.62059, val_loss= 0.75479, val_acc= 0.50800, time= 1.28160\n",
      "[2022/4/20 13:46:10] Epoch: 48, train_loss= 0.69659, train_acc= 0.62059, val_loss= 0.75418, val_acc= 0.50400, time= 1.23979\n",
      "[2022/4/20 13:46:11] Epoch: 49, train_loss= 0.69602, train_acc= 0.62094, val_loss= 0.75353, val_acc= 0.50400, time= 1.21411\n",
      "[2022/4/20 13:46:13] Epoch: 50, train_loss= 0.69517, train_acc= 0.62094, val_loss= 0.75300, val_acc= 0.50400, time= 1.26203\n",
      "[2022/4/20 13:46:14] Epoch: 51, train_loss= 0.87226, train_acc= 0.62082, val_loss= 0.74926, val_acc= 0.50600, time= 1.23784\n",
      "[2022/4/20 13:46:15] Epoch: 52, train_loss= 0.69802, train_acc= 0.61494, val_loss= 0.74546, val_acc= 0.50600, time= 1.21370\n",
      "[2022/4/20 13:46:16] Epoch: 53, train_loss= 0.69893, train_acc= 0.61306, val_loss= 0.74266, val_acc= 0.50600, time= 1.21981\n",
      "[2022/4/20 13:46:18] Epoch: 54, train_loss= 0.69904, train_acc= 0.61412, val_loss= 0.74047, val_acc= 0.51000, time= 1.26217\n",
      "[2022/4/20 13:46:19] Epoch: 55, train_loss= 0.69846, train_acc= 0.61412, val_loss= 0.73857, val_acc= 0.50600, time= 1.24849\n",
      "[2022/4/20 13:46:20] Epoch: 56, train_loss= 0.69758, train_acc= 0.61624, val_loss= 0.73690, val_acc= 0.50400, time= 1.25768\n",
      "[2022/4/20 13:46:21] Epoch: 57, train_loss= 0.69682, train_acc= 0.61741, val_loss= 0.73522, val_acc= 0.50800, time= 1.23709\n",
      "[2022/4/20 13:46:23] Epoch: 58, train_loss= 0.69620, train_acc= 0.61776, val_loss= 0.73371, val_acc= 0.50800, time= 1.22858\n",
      "[2022/4/20 13:46:24] Epoch: 59, train_loss= 0.69575, train_acc= 0.61906, val_loss= 0.73241, val_acc= 0.50400, time= 1.25598\n",
      "[2022/4/20 13:46:25] Epoch: 60, train_loss= 0.69541, train_acc= 0.61929, val_loss= 0.73131, val_acc= 0.50200, time= 1.24035\n",
      "[2022/4/20 13:46:26] Epoch: 61, train_loss= 0.69514, train_acc= 0.61988, val_loss= 0.73037, val_acc= 0.50200, time= 1.24353\n",
      "[2022/4/20 13:46:28] Epoch: 62, train_loss= 0.69488, train_acc= 0.62035, val_loss= 0.72956, val_acc= 0.50600, time= 1.24224\n",
      "[2022/4/20 13:46:29] Epoch: 63, train_loss= 0.69467, train_acc= 0.61918, val_loss= 0.72891, val_acc= 0.50400, time= 1.27597\n",
      "[2022/4/20 13:46:30] Epoch: 64, train_loss= 0.69449, train_acc= 0.61894, val_loss= 0.72838, val_acc= 0.50200, time= 1.25386\n",
      "[2022/4/20 13:46:31] Epoch: 65, train_loss= 0.69436, train_acc= 0.61788, val_loss= 0.72794, val_acc= 0.50000, time= 1.24659\n",
      "[2022/4/20 13:46:33] Epoch: 66, train_loss= 0.69428, train_acc= 0.61718, val_loss= 0.72755, val_acc= 0.50200, time= 1.23124\n",
      "[2022/4/20 13:46:34] Epoch: 67, train_loss= 0.69426, train_acc= 0.61612, val_loss= 0.72718, val_acc= 0.51200, time= 1.21266\n",
      "[2022/4/20 13:46:35] Epoch: 68, train_loss= 0.69430, train_acc= 0.61506, val_loss= 0.72682, val_acc= 0.51600, time= 1.25249\n",
      "[2022/4/20 13:46:36] Epoch: 69, train_loss= 0.69437, train_acc= 0.61435, val_loss= 0.72641, val_acc= 0.51400, time= 1.24650\n",
      "[2022/4/20 13:46:38] Epoch: 70, train_loss= 0.69444, train_acc= 0.61459, val_loss= 0.72595, val_acc= 0.51600, time= 1.25758\n",
      "[2022/4/20 13:46:39] Epoch: 71, train_loss= 0.69451, train_acc= 0.61306, val_loss= 0.72544, val_acc= 0.51400, time= 1.24903\n",
      "[2022/4/20 13:46:40] Epoch: 72, train_loss= 0.69453, train_acc= 0.61259, val_loss= 0.72486, val_acc= 0.51200, time= 1.23859\n",
      "[2022/4/20 13:46:41] Epoch: 73, train_loss= 0.69452, train_acc= 0.61282, val_loss= 0.72426, val_acc= 0.51000, time= 1.25328\n",
      "[2022/4/20 13:46:43] Epoch: 74, train_loss= 0.69448, train_acc= 0.61235, val_loss= 0.72362, val_acc= 0.51200, time= 1.22710\n",
      "[2022/4/20 13:46:44] Epoch: 75, train_loss= 0.69443, train_acc= 0.61271, val_loss= 0.72299, val_acc= 0.51200, time= 1.25647\n",
      "[2022/4/20 13:46:45] Epoch: 76, train_loss= 0.69437, train_acc= 0.61294, val_loss= 0.72237, val_acc= 0.51400, time= 1.25425\n",
      "[2022/4/20 13:46:46] Epoch: 77, train_loss= 0.69432, train_acc= 0.61282, val_loss= 0.72175, val_acc= 0.51000, time= 1.24385\n",
      "[2022/4/20 13:46:48] Epoch: 78, train_loss= 0.69427, train_acc= 0.61294, val_loss= 0.72116, val_acc= 0.50800, time= 1.24618\n",
      "[2022/4/20 13:46:49] Epoch: 79, train_loss= 0.69422, train_acc= 0.61271, val_loss= 0.72057, val_acc= 0.50600, time= 1.23929\n",
      "[2022/4/20 13:46:50] Epoch: 80, train_loss= 0.69417, train_acc= 0.61294, val_loss= 0.72001, val_acc= 0.50600, time= 1.23869\n",
      "[2022/4/20 13:46:51] Epoch: 81, train_loss= 0.69412, train_acc= 0.61318, val_loss= 0.71947, val_acc= 0.50800, time= 1.26496\n",
      "[2022/4/20 13:46:53] Epoch: 82, train_loss= 0.69407, train_acc= 0.61318, val_loss= 0.71896, val_acc= 0.50400, time= 1.30933\n",
      "[2022/4/20 13:46:54] Epoch: 83, train_loss= 0.69403, train_acc= 0.61235, val_loss= 0.71849, val_acc= 0.50400, time= 1.31479\n",
      "[2022/4/20 13:46:55] Epoch: 84, train_loss= 0.69399, train_acc= 0.61247, val_loss= 0.71803, val_acc= 0.50400, time= 1.27742\n",
      "[2022/4/20 13:46:56] Epoch: 85, train_loss= 0.69396, train_acc= 0.61306, val_loss= 0.71761, val_acc= 0.50800, time= 1.26904\n",
      "[2022/4/20 13:46:58] Epoch: 86, train_loss= 0.69394, train_acc= 0.61235, val_loss= 0.71720, val_acc= 0.50800, time= 1.25832\n",
      "[2022/4/20 13:46:59] Epoch: 87, train_loss= 0.69392, train_acc= 0.61235, val_loss= 0.71680, val_acc= 0.51200, time= 1.25544\n",
      "[2022/4/20 13:47:00] Epoch: 88, train_loss= 0.69391, train_acc= 0.61188, val_loss= 0.71641, val_acc= 0.51200, time= 1.35206\n",
      "[2022/4/20 13:47:02] Epoch: 89, train_loss= 0.69389, train_acc= 0.61176, val_loss= 0.71602, val_acc= 0.51000, time= 1.32720\n",
      "[2022/4/20 13:47:03] Epoch: 90, train_loss= 0.69386, train_acc= 0.61165, val_loss= 0.71563, val_acc= 0.51000, time= 1.26699\n",
      "[2022/4/20 13:47:04] Epoch: 91, train_loss= 0.69385, train_acc= 0.61188, val_loss= 0.71524, val_acc= 0.51000, time= 1.24671\n",
      "[2022/4/20 13:47:05] Epoch: 92, train_loss= 0.69383, train_acc= 0.61188, val_loss= 0.71486, val_acc= 0.51200, time= 1.24605\n",
      "[2022/4/20 13:47:07] Epoch: 93, train_loss= 0.69381, train_acc= 0.61200, val_loss= 0.71445, val_acc= 0.51200, time= 1.31548\n",
      "[2022/4/20 13:47:08] Epoch: 94, train_loss= 0.69378, train_acc= 0.61200, val_loss= 0.71408, val_acc= 0.51600, time= 1.26901\n",
      "[2022/4/20 13:47:09] Epoch: 95, train_loss= 0.69376, train_acc= 0.61200, val_loss= 0.71372, val_acc= 0.51200, time= 1.28027\n",
      "[2022/4/20 13:47:11] Epoch: 96, train_loss= 0.69373, train_acc= 0.61212, val_loss= 0.71337, val_acc= 0.51200, time= 1.28972\n",
      "[2022/4/20 13:47:12] Epoch: 97, train_loss= 0.69372, train_acc= 0.61235, val_loss= 0.71301, val_acc= 0.51200, time= 1.27008\n",
      "[2022/4/20 13:47:13] Epoch: 98, train_loss= 0.69369, train_acc= 0.61235, val_loss= 0.71264, val_acc= 0.51400, time= 1.26405\n",
      "[2022/4/20 13:47:14] Epoch: 99, train_loss= 0.69365, train_acc= 0.61294, val_loss= 0.71230, val_acc= 0.51600, time= 1.26341\n",
      "[2022/4/20 13:47:16] Epoch: 100, train_loss= 0.69362, train_acc= 0.61365, val_loss= 0.71198, val_acc= 0.51400, time= 1.27242\n",
      "[2022/4/20 13:47:16] Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(t_features)\n",
    "    loss = criterion(logits * tm_train_mask, torch.max(t_y_train, 1)[1])    \n",
    "    acc = ((torch.max(logits, 1)[1] == torch.max(t_y_train, 1)[1]).float() * t_train_mask).sum().item() / t_train_mask.sum().item()\n",
    "        \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_acc, pred, labels, duration = evaluate(t_features, t_y_val, val_mask)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print_log(\"Epoch: {:.0f}, train_loss= {:.5f}, train_acc= {:.5f}, val_loss= {:.5f}, val_acc= {:.5f}, time= {:.5f}\"\\\n",
    "                .format(epoch + 1, loss, acc, val_loss, val_acc, time.time() - t))\n",
    "\n",
    "    # if epoch > 5 and val_losses[-1] > np.mean(val_losses[-(5+1):-1]):\n",
    "    #     print_log(\"Early stopping...\")\n",
    "    #     break\n",
    "\n",
    "\n",
    "print_log(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bis/Projects/venv3.6/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/4/20 13:44:45] Test set results: \n",
      "[2022/4/20 13:44:45] \t loss= 0.70657, accuracy= 0.51600, time= 0.48989\n",
      "[2022/4/20 13:44:45] Test Precision, Recall and F1-Score...\n",
      "[2022/4/20 13:44:45]               precision    recall  f1-score   support\n",
      "[2022/4/20 13:44:45] \n",
      "[2022/4/20 13:44:45]            0     0.5159    0.8294    0.6361       510\n",
      "[2022/4/20 13:44:45]            1     0.5167    0.1898    0.2776       490\n",
      "[2022/4/20 13:44:45] \n",
      "[2022/4/20 13:44:45]     accuracy                         0.5160      1000\n",
      "[2022/4/20 13:44:45]    macro avg     0.5163    0.5096    0.4569      1000\n",
      "[2022/4/20 13:44:45] weighted avg     0.5163    0.5160    0.4604      1000\n",
      "[2022/4/20 13:44:45] \n",
      "[2022/4/20 13:44:45] Macro average Test Precision, Recall and F1-Score...\n",
      "[2022/4/20 13:44:45] (0.5162601626016261, 0.5096038415366146, 0.4568510829312087, None)\n",
      "[2022/4/20 13:44:45] Micro average Test Precision, Recall and F1-Score...\n",
      "[2022/4/20 13:44:45] (0.516, 0.516, 0.516, None)\n",
      "[2022/4/20 13:44:45] Auc Score test ...\n",
      "[2022/4/20 13:44:45] 0.5096038415366146\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_loss, test_acc, pred, labels, test_duration = evaluate(t_features, t_y_test, test_mask)\n",
    "print_log(\"Test set results: \\n\\t loss= {:.5f}, accuracy= {:.5f}, time= {:.5f}\".format(test_loss, test_acc, test_duration))\n",
    "\n",
    "test_pred = []\n",
    "test_labels = []\n",
    "for i in range(len(test_mask)):\n",
    "    if test_mask[i]:\n",
    "        test_pred.append(pred[i])\n",
    "        test_labels.append(np.argmax(labels[i]))\n",
    "\n",
    "\n",
    "print_log(\"Test Precision, Recall and F1-Score...\")\n",
    "print_log(metrics.classification_report(test_labels, test_pred, digits=4))\n",
    "print_log(\"Macro average Test Precision, Recall and F1-Score...\")\n",
    "print_log(metrics.precision_recall_fscore_support(test_labels, test_pred, average='macro'))\n",
    "print_log(\"Micro average Test Precision, Recall and F1-Score...\")\n",
    "print_log(metrics.precision_recall_fscore_support(test_labels, test_pred, average='micro'))\n",
    "\n",
    "print_log(\"Auc Score test ...\")\n",
    "print_log(metrics.roc_auc_score(test_labels, test_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9188de91555ba3328945728ae07a43dc8dfe643542d510c5729b810ec16c80f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 ('venv3.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
