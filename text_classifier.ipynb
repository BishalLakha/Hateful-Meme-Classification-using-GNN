{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "import numpy as np\n",
    "\n",
    "from utils.utils import *\n",
    "from models.gcn import GCN\n",
    "from models.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading graph\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus()\n",
    "features = sp.identity(features.shape[0])\n",
    "features = preprocess_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23551, 23551)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading image features\n",
    "train_embeddings, test_embeddings = get_image_embeddings()\n",
    "training_embeddings = torch.tensor(train_embeddings).reshape(train_size,512)\n",
    "test_embeddings = torch.tensor(test_embeddings).reshape(test_size,512)\n",
    "\n",
    "\n",
    "# Getting complete features for all nodes\n",
    "word_nodes = features.shape[0] - train_size - test_size\n",
    "\n",
    "# Since we don't have image embeddings for words, we will use zeros\n",
    "image_embeddings_words = torch.zeros(word_nodes,512)\n",
    "\n",
    "all_image_features = torch.cat((training_embeddings, image_embeddings_words, test_embeddings), 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2074, -0.2249, -0.0530,  ...,  0.0562,  0.0360,  0.0046],\n",
       "        [ 0.3254,  0.1113, -0.0094,  ..., -0.0314,  0.4260, -0.3494],\n",
       "        [ 0.1094, -0.4641, -0.1338,  ...,  0.0568,  0.0364, -0.1023],\n",
       "        ...,\n",
       "        [-0.2140, -0.1322,  0.0471,  ...,  0.2145,  0.1888, -0.2120],\n",
       "        [-0.0359,  0.0592,  0.2881,  ...,  0.5137, -0.0331,  0.1102],\n",
       "        [ 0.0183,  0.2300, -0.2666,  ...,  0.0280,  0.0512,  0.0186]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_adj(adj):\n",
    "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
    "    adj = sp.coo_matrix(adj + sp.eye(adj.shape[0]))\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "adjdense = torch.from_numpy(pre_adj(adj).A.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True\n",
    "def construct_graph(adjacency):\n",
    "    g = DGLGraph()\n",
    "    adj = pre_adj(adjacency)\n",
    "    g.add_nodes(adj.shape[0])\n",
    "    g.add_edges(adj.row,adj.col)\n",
    "    adjdense = adj.A\n",
    "    adjd = np.ones((adj.shape[0]))\n",
    "    for i in range(adj.shape[0]):\n",
    "        adjd[i] = adjd[i] * np.sum(adjdense[i,:])\n",
    "    weight = torch.from_numpy(adj.data.astype(np.float32))\n",
    "    g.ndata['d'] = torch.from_numpy(adjd.astype(np.float32))\n",
    "    g.edata['w'] = weight\n",
    "\n",
    "    if CUDA:\n",
    "        g = g.to(torch.device('cuda:0'))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv(nn.Module):\n",
    "    def __init__(self,g,in_feats,out_feats,activation,feat_drop=True):\n",
    "        super(SimpleConv, self).__init__()\n",
    "        self.graph = g\n",
    "        self.activation = activation\n",
    "        #self.reset_parameters()\n",
    "        setattr(self, 'W', nn.Parameter(torch.randn(in_feats,out_feats)))\n",
    "        #self.b = nn.Parameter(torch.zeros(1, out_feats))\n",
    "        #self.linear = nn.Linear(in_feats,out_feats)\n",
    "        self.feat_drop = feat_drop\n",
    "    \n",
    "    # def reset_parameters(self):\n",
    "    #     gain = nn.init.calculate_gain('relu')\n",
    "    #     nn.init.xavier_uniform_(self.linear.weight,gain=gain)\n",
    "    \n",
    "    def forward(self, feat):\n",
    "        g = self.graph.local_var()\n",
    "        g.ndata['h'] = feat.mm(getattr(self, 'W'))\n",
    "        g.update_all(fn.src_mul_edge(src='h', edge='w', out='m'), fn.sum(msg='m',out='h'))\n",
    "        rst = g.ndata['h']\n",
    "        #rst = self.linear(rst)\n",
    "        rst = self.activation(rst)\n",
    "        return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifer(nn.Module):\n",
    "    def __init__(self,g,input_dim,num_classes,conv):\n",
    "        super(Classifer, self).__init__()\n",
    "        self.data_graph = g\n",
    "        self.GCN = conv\n",
    "        self.gcn1 = self.GCN(g,input_dim, 300, F.relu)\n",
    "        self.gcn2 = self.GCN(g, 300, 200, F.relu)\n",
    "        self.gcn3 = self.GCN(g, 200, num_classes, F.relu)\n",
    "\n",
    "    \n",
    "    def forward(self, features):\n",
    "        x = self.gcn1(features)\n",
    "\n",
    "        # To Do: Fuse the text embedding with image embedding \n",
    "        self.embedding = x\n",
    "        # x = torch.cat(x,g.ndata['x'])\n",
    "        # x = torch.cat((self.embedding,g.ndata['x']),dim=1)\n",
    "        x = self.gcn2(x)\n",
    "        x = self.gcn3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ClassiferFusion(nn.Module):\n",
    "    def __init__(self,g,input_dim,num_classes,conv):\n",
    "        super(Classifer, self).__init__()\n",
    "        self.data_graph = g\n",
    "        self.GCN = conv\n",
    "        self.gcn1 = self.GCN(g,input_dim, 300, F.relu)\n",
    "        self.gcn2 = self.GCN(g, 300, 200, F.relu)\n",
    "        self.gcn3 = self.GCN(g, 100, num_classes, F.relu)\n",
    "\n",
    "    \n",
    "    def forward(self, features):\n",
    "        x = self.gcn1(features)\n",
    "\n",
    "        # To Do: Fuse the text embedding with image embedding \n",
    "        self.embedding = x\n",
    "        # x = torch.cat(x,g.ndata['x'])\n",
    "        x = torch.cat((self.embedding,g.ndata['x']),dim=1)\n",
    "        x = self.gcn2(x)\n",
    "        x = self.gcn3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bis/Projects/venv3.6/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "g = construct_graph(adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifer(g,input_dim=features.shape[0], num_classes=y_train.shape[1],conv=SimpleConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "t_features = torch.from_numpy(features.astype(np.float32))\n",
    "t_y_train = torch.from_numpy(y_train)\n",
    "t_y_val = torch.from_numpy(y_val)\n",
    "t_y_test = torch.from_numpy(y_test)\n",
    "t_train_mask = torch.from_numpy(train_mask.astype(np.float32))\n",
    "tm_train_mask = torch.transpose(torch.unsqueeze(t_train_mask, 0), 1, 0).repeat(1, y_train.shape[1])\n",
    "support = [preprocess_adj(adj)]\n",
    "num_supports = 1\n",
    "t_support = []\n",
    "for i in range(len(support)):\n",
    "    t_support.append(torch.Tensor(support[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_features = t_features.cuda()\n",
    "t_y_train = t_y_train.cuda()\n",
    "#t_y_val = t_y_val.cuda()\n",
    "#t_y_test = t_y_test.cuda()\n",
    "t_train_mask = t_train_mask.cuda()\n",
    "tm_train_mask = tm_train_mask.cuda()\n",
    "# for i in range(len(support)):\n",
    "#     t_support = [t.cuda() for t in t_support if True]\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(features, labels, mask):\n",
    "    t_test = time.time()\n",
    "    # feed_dict_val = construct_feed_dict(\n",
    "    #     features, support, labels, mask, placeholders)\n",
    "    # outs_val = sess.run([model.loss, model.accuracy, model.pred, model.labels], feed_dict=feed_dict_val)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features).cpu()\n",
    "        t_mask = torch.from_numpy(np.array(mask*1., dtype=np.float32))\n",
    "        tm_mask = torch.transpose(torch.unsqueeze(t_mask, 0), 1, 0).repeat(1, labels.shape[1])\n",
    "        loss = criterion(logits * tm_mask, torch.max(labels, 1)[1])\n",
    "        pred = torch.max(logits, 1)[1]\n",
    "        acc = ((pred == torch.max(labels, 1)[1]).float() * t_mask).sum().item() / t_mask.sum().item()\n",
    "        \n",
    "    return loss.numpy(), acc, pred.numpy(), labels.numpy(), (time.time() - t_test)\n",
    "\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/4/4 18:56:58] Epoch: 1, train_loss= 2.65577, train_acc= 0.37435, val_loss= 1.67588, val_acc= 0.51800, time= 0.67278\n",
      "[2022/4/4 18:56:58] Epoch: 2, train_loss= 2.05875, train_acc= 0.38706, val_loss= 1.64236, val_acc= 0.53200, time= 0.62460\n",
      "[2022/4/4 18:56:59] Epoch: 3, train_loss= 1.54058, train_acc= 0.41576, val_loss= 1.61902, val_acc= 0.52200, time= 0.62247\n",
      "[2022/4/4 18:57:00] Epoch: 4, train_loss= 1.20177, train_acc= 0.48835, val_loss= 1.60657, val_acc= 0.52200, time= 0.62568\n",
      "[2022/4/4 18:57:00] Epoch: 5, train_loss= 1.13552, train_acc= 0.56788, val_loss= 1.60399, val_acc= 0.51200, time= 0.62609\n",
      "[2022/4/4 18:57:01] Epoch: 6, train_loss= 1.23361, train_acc= 0.60165, val_loss= 1.60470, val_acc= 0.50600, time= 0.63442\n",
      "[2022/4/4 18:57:01] Epoch: 7, train_loss= 1.34360, train_acc= 0.61765, val_loss= 1.60545, val_acc= 0.50400, time= 0.64002\n",
      "[2022/4/4 18:57:02] Epoch: 8, train_loss= 1.41096, train_acc= 0.62553, val_loss= 1.60470, val_acc= 0.51000, time= 0.63683\n",
      "[2022/4/4 18:57:03] Epoch: 9, train_loss= 1.42833, train_acc= 0.62765, val_loss= 1.60220, val_acc= 0.50800, time= 0.63251\n",
      "[2022/4/4 18:57:03] Epoch: 10, train_loss= 1.40151, train_acc= 0.62847, val_loss= 1.59834, val_acc= 0.50600, time= 0.64209\n",
      "[2022/4/4 18:57:04] Epoch: 11, train_loss= 1.33998, train_acc= 0.62576, val_loss= 1.59387, val_acc= 0.50200, time= 0.64070\n",
      "[2022/4/4 18:57:05] Epoch: 12, train_loss= 1.25498, train_acc= 0.62141, val_loss= 1.58990, val_acc= 0.50600, time= 0.62165\n",
      "[2022/4/4 18:57:05] Epoch: 13, train_loss= 1.16044, train_acc= 0.61400, val_loss= 1.58750, val_acc= 0.51400, time= 0.63518\n",
      "[2022/4/4 18:57:06] Epoch: 14, train_loss= 1.07450, train_acc= 0.60565, val_loss= 1.58631, val_acc= 0.51800, time= 0.64180\n",
      "[2022/4/4 18:57:07] Epoch: 15, train_loss= 1.01738, train_acc= 0.58847, val_loss= 1.58626, val_acc= 0.52800, time= 0.61740\n",
      "[2022/4/4 18:57:07] Epoch: 16, train_loss= 1.00318, train_acc= 0.56035, val_loss= 1.58712, val_acc= 0.53200, time= 0.63349\n",
      "[2022/4/4 18:57:08] Epoch: 17, train_loss= 1.02603, train_acc= 0.52800, val_loss= 1.58774, val_acc= 0.53200, time= 0.65678\n",
      "[2022/4/4 18:57:08] Epoch: 18, train_loss= 1.06026, train_acc= 0.50694, val_loss= 1.58692, val_acc= 0.53400, time= 0.62904\n",
      "[2022/4/4 18:57:09] Epoch: 19, train_loss= 1.07900, train_acc= 0.49671, val_loss= 1.58425, val_acc= 0.53400, time= 0.67476\n",
      "[2022/4/4 18:57:10] Epoch: 20, train_loss= 1.06905, train_acc= 0.49894, val_loss= 1.58008, val_acc= 0.53200, time= 0.63326\n",
      "[2022/4/4 18:57:10] Epoch: 21, train_loss= 1.03264, train_acc= 0.51082, val_loss= 1.57519, val_acc= 0.53200, time= 0.62282\n",
      "[2022/4/4 18:57:11] Epoch: 22, train_loss= 0.98265, train_acc= 0.53188, val_loss= 1.57033, val_acc= 0.52800, time= 0.61926\n",
      "[2022/4/4 18:57:12] Epoch: 23, train_loss= 0.93637, train_acc= 0.55894, val_loss= 1.56613, val_acc= 0.51600, time= 0.61553\n",
      "[2022/4/4 18:57:12] Epoch: 24, train_loss= 0.90733, train_acc= 0.59059, val_loss= 1.56254, val_acc= 0.51400, time= 0.61510\n",
      "[2022/4/4 18:57:13] Epoch: 25, train_loss= 0.89880, train_acc= 0.61024, val_loss= 1.55928, val_acc= 0.50800, time= 0.60797\n",
      "[2022/4/4 18:57:13] Epoch: 26, train_loss= 0.90395, train_acc= 0.62624, val_loss= 1.55665, val_acc= 0.51000, time= 0.60834\n",
      "[2022/4/4 18:57:14] Epoch: 27, train_loss= 0.91172, train_acc= 0.63435, val_loss= 1.55431, val_acc= 0.50600, time= 0.62351\n",
      "[2022/4/4 18:57:15] Epoch: 28, train_loss= 0.91320, train_acc= 0.64047, val_loss= 1.55205, val_acc= 0.50600, time= 0.61850\n",
      "[2022/4/4 18:57:15] Epoch: 29, train_loss= 0.90422, train_acc= 0.64235, val_loss= 1.54974, val_acc= 0.50600, time= 0.60905\n",
      "[2022/4/4 18:57:16] Epoch: 30, train_loss= 0.88534, train_acc= 0.64400, val_loss= 1.54748, val_acc= 0.50800, time= 0.60964\n",
      "[2022/4/4 18:57:17] Epoch: 31, train_loss= 0.86080, train_acc= 0.64353, val_loss= 1.54541, val_acc= 0.51000, time= 0.60060\n",
      "[2022/4/4 18:57:17] Epoch: 32, train_loss= 0.83697, train_acc= 0.63824, val_loss= 1.54372, val_acc= 0.51400, time= 0.60706\n",
      "[2022/4/4 18:57:18] Epoch: 33, train_loss= 0.81990, train_acc= 0.62988, val_loss= 1.54225, val_acc= 0.51600, time= 0.60517\n",
      "[2022/4/4 18:57:18] Epoch: 34, train_loss= 0.81228, train_acc= 0.62141, val_loss= 1.54067, val_acc= 0.51400, time= 0.60653\n",
      "[2022/4/4 18:57:19] Epoch: 35, train_loss= 0.81177, train_acc= 0.61153, val_loss= 1.53882, val_acc= 0.51200, time= 0.60780\n",
      "[2022/4/4 18:57:20] Epoch: 36, train_loss= 0.81240, train_acc= 0.60306, val_loss= 1.53658, val_acc= 0.51200, time= 0.61438\n",
      "[2022/4/4 18:57:20] Epoch: 37, train_loss= 0.80850, train_acc= 0.60118, val_loss= 1.53396, val_acc= 0.51200, time= 0.60175\n",
      "[2022/4/4 18:57:21] Epoch: 38, train_loss= 0.79805, train_acc= 0.60741, val_loss= 1.53107, val_acc= 0.51400, time= 0.61580\n",
      "[2022/4/4 18:57:21] Epoch: 39, train_loss= 0.78316, train_acc= 0.61976, val_loss= 1.52808, val_acc= 0.51400, time= 0.62182\n",
      "[2022/4/4 18:57:22] Epoch: 40, train_loss= 0.76839, train_acc= 0.63835, val_loss= 1.52498, val_acc= 0.51800, time= 0.60511\n",
      "[2022/4/4 18:57:23] Epoch: 41, train_loss= 0.75767, train_acc= 0.65071, val_loss= 1.52213, val_acc= 0.51200, time= 0.61131\n",
      "[2022/4/4 18:57:23] Epoch: 42, train_loss= 0.75208, train_acc= 0.66271, val_loss= 1.51948, val_acc= 0.51200, time= 0.61026\n",
      "[2022/4/4 18:57:24] Epoch: 43, train_loss= 0.74969, train_acc= 0.66859, val_loss= 1.51706, val_acc= 0.51200, time= 0.62268\n",
      "[2022/4/4 18:57:24] Epoch: 44, train_loss= 0.74729, train_acc= 0.67529, val_loss= 1.51477, val_acc= 0.51200, time= 0.60857\n",
      "[2022/4/4 18:57:25] Epoch: 45, train_loss= 0.74243, train_acc= 0.67929, val_loss= 1.51248, val_acc= 0.51200, time= 0.60500\n",
      "[2022/4/4 18:57:26] Epoch: 46, train_loss= 0.73464, train_acc= 0.68071, val_loss= 1.51022, val_acc= 0.51200, time= 0.61675\n",
      "[2022/4/4 18:57:26] Epoch: 47, train_loss= 0.72529, train_acc= 0.68224, val_loss= 1.50807, val_acc= 0.51400, time= 0.61643\n",
      "[2022/4/4 18:57:27] Epoch: 48, train_loss= 0.71667, train_acc= 0.68424, val_loss= 1.50608, val_acc= 0.51800, time= 0.60558\n",
      "[2022/4/4 18:57:28] Epoch: 49, train_loss= 0.71056, train_acc= 0.68047, val_loss= 1.50423, val_acc= 0.52000, time= 0.61466\n",
      "[2022/4/4 18:57:28] Epoch: 50, train_loss= 0.70706, train_acc= 0.67694, val_loss= 1.50236, val_acc= 0.51800, time= 0.60708\n",
      "[2022/4/4 18:57:28] Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(t_features)\n",
    "    loss = criterion(logits * tm_train_mask, torch.max(t_y_train, 1)[1])    \n",
    "    acc = ((torch.max(logits, 1)[1] == torch.max(t_y_train, 1)[1]).float() * t_train_mask).sum().item() / t_train_mask.sum().item()\n",
    "        \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_acc, pred, labels, duration = evaluate(t_features, t_y_val, val_mask)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print_log(\"Epoch: {:.0f}, train_loss= {:.5f}, train_acc= {:.5f}, val_loss= {:.5f}, val_acc= {:.5f}, time= {:.5f}\"\\\n",
    "                .format(epoch + 1, loss, acc, val_loss, val_acc, time.time() - t))\n",
    "\n",
    "    # if epoch > 5 and val_losses[-1] > np.mean(val_losses[-(5+1):-1]):\n",
    "    #     print_log(\"Early stopping...\")\n",
    "    #     break\n",
    "\n",
    "\n",
    "print_log(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/4/4 18:57:31] Test set results: \n",
      "[2022/4/4 18:57:31] \t loss= 0.79779, accuracy= 0.52000, time= 0.26450\n",
      "[2022/4/4 18:57:31] Test Precision, Recall and F1-Score...\n",
      "[2022/4/4 18:57:31]               precision    recall  f1-score   support\n",
      "[2022/4/4 18:57:31] \n",
      "[2022/4/4 18:57:31]            0     0.5254    0.6078    0.5636       510\n",
      "[2022/4/4 18:57:31]            1     0.5122    0.4286    0.4667       490\n",
      "[2022/4/4 18:57:31] \n",
      "[2022/4/4 18:57:31]     accuracy                         0.5200      1000\n",
      "[2022/4/4 18:57:31]    macro avg     0.5188    0.5182    0.5152      1000\n",
      "[2022/4/4 18:57:31] weighted avg     0.5189    0.5200    0.5161      1000\n",
      "[2022/4/4 18:57:31] \n",
      "[2022/4/4 18:57:31] Macro average Test Precision, Recall and F1-Score...\n",
      "[2022/4/4 18:57:31] (0.5188094253823894, 0.5182072829131652, 0.5151515151515151, None)\n",
      "[2022/4/4 18:57:31] Micro average Test Precision, Recall and F1-Score...\n",
      "[2022/4/4 18:57:31] (0.52, 0.52, 0.52, None)\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_loss, test_acc, pred, labels, test_duration = evaluate(t_features, t_y_test, test_mask)\n",
    "print_log(\"Test set results: \\n\\t loss= {:.5f}, accuracy= {:.5f}, time= {:.5f}\".format(test_loss, test_acc, test_duration))\n",
    "\n",
    "test_pred = []\n",
    "test_labels = []\n",
    "for i in range(len(test_mask)):\n",
    "    if test_mask[i]:\n",
    "        test_pred.append(pred[i])\n",
    "        test_labels.append(np.argmax(labels[i]))\n",
    "\n",
    "\n",
    "print_log(\"Test Precision, Recall and F1-Score...\")\n",
    "print_log(metrics.classification_report(test_labels, test_pred, digits=4))\n",
    "print_log(\"Macro average Test Precision, Recall and F1-Score...\")\n",
    "print_log(metrics.precision_recall_fscore_support(test_labels, test_pred, average='macro'))\n",
    "print_log(\"Micro average Test Precision, Recall and F1-Score...\")\n",
    "print_log(metrics.precision_recall_fscore_support(test_labels, test_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9188de91555ba3328945728ae07a43dc8dfe643542d510c5729b810ec16c80f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 ('venv3.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
